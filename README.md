[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/rjgbNS53)
Arbetsg√•ng
1. Datainsamling fr√•n EUvsDisinfo. Kanske komplettera med fler sidor som √§ven har sann fakta.
2. F√∂rbehandla text
3. Tr√§na ML-Modell
4. Skapa en API-server f√∂r anv√§ndning av extension via HTTP-anrop
5. Bygga extension

# Swedish News Disinformation Detector

Detta projekt √§r ett grupparbete som utvecklar en Streamlit-app f√∂r att klassificera svenska nyhetsartiklar som trov√§rdiga eller vilseledande, med hj√§lp av en fintr√§nad RoBERTa-modell.

## üöÄ Snabbstart

### 1. Klona repot
```sh
git clone https://github.com/SVP-GU/group-project-group-16.git
cd group-project-group-16
```

### 2. Installera beroenden
Vi rekommenderar att anv√§nda en virtuell milj√∂:
```sh
pip install -r requirements.txt
```

### 3. Starta appen
```sh
streamlit run app.py --browser.gatherUsageStats false
```
Appen √∂ppnas i din webbl√§sare p√• [http://localhost:8501](http://localhost:8501).

## üì∞ Funktioner
- Klistra in en nyhetsartikel och analysera dess trov√§rdighet.
- Bygger p√• Hugging Face-modellen [`Mirac1999/roberta-new-classifier-2.0`](https://huggingface.co/Mirac1999/roberta-new-classifier-2.0).
- Resultat visas direkt i webbl√§saren.

## üìä Modell och Prestanda
- **Modell:** RoBERTa (XLM-RoBERTa-base) fintr√§nad p√• svenska nyhetsartiklar
- **Valideringsresultat:**
  - Accuracy: 0.76
  - Macro F1: 0.76
  - Klass 0 (trov√§rdig): Precision 0.83, Recall 0.77, F1 0.80
  - Klass 1 (misinformation): Precision 0.68, Recall 0.75, F1 0.72

## üìö Dataset
Modellen √§r tr√§nad p√• ett sammansatt dataset av √∂ver 38 000 svenska nyhetsartiklar, h√§mtade fr√•n b√•de legitima nyhetsk√§llor och k√§nda desinformationsk√§llor (t.ex. EUvsDisinfo). Datasetet har f√∂rbehandlats och balanserats f√∂r att f√∂rb√§ttra modellens f√∂rm√•ga att s√§rskilja mellan trov√§rdig och vilseledande information.

## üõ†Ô∏è Exempel p√• anv√§ndning i kod
Vill du anv√§nda modellen direkt i Python?
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

tokenizer = AutoTokenizer.from_pretrained("Mirac1999/roberta-new-classifier-2.0")
model = AutoModelForSequenceClassification.from_pretrained("Mirac1999/roberta-new-classifier-2.0")

text = "Sveriges regering meddelade idag nya √•tg√§rder f√∂r att bek√§mpa klimatf√∂r√§ndringarna."
inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
with torch.no_grad():
    outputs = model(**inputs)
    probabilities = torch.softmax(outputs.logits, dim=1)
    prediction = torch.argmax(probabilities, dim=1).item()
    confidence = probabilities[0][prediction].item()

print(f"Trov√§rdig: {prediction == 1}, Konfidens: {confidence:.2%}")
```

## ü§ù Bidra
Pull requests och f√∂rb√§ttringsf√∂rslag v√§lkomnas! Projektet √§r ett grupparbete inom kursen TIG321 p√• G√∂teborgs universitet.

## üìÑ Licens
Se LICENSE-filen i repot.

## üìä Modellens Prestanda
- Accuracy: 77.1%
- Precision f√∂r trov√§rdiga nyheter: 88.5%
- Recall f√∂r vilseledande nyheter: 85.6%

## üõ†Ô∏è Fels√∂kning

Om du f√•r problem, kontrollera f√∂ljande:

1. **ModuleNotFoundError**: K√∂r `pip install transformers torch` igen
2. **CUDA-fel**: Om du har problem med GPU, l√§gg till denna kod f√∂re modell-laddningen:
   ```python
   import torch
   device = "cuda" if torch.cuda.is_available() else "cpu"
   model = model.to(device)
   ```
3. **Minnesfel**: Om du f√•r minnesfel, minska `max_length` i tokenizer-anropet

## üîç Tekniska Detaljer

### Modellarkitektur
- Basmodell: KB/bert-base-swedish-cased (Swedish BERT)
- Finjusterad p√• v√•r egen dataset av svenska nyhetsartiklar
- St√∂d f√∂r b√•de svenska och engelska texter

### Dataset
Modellen √§r tr√§nad p√• 38,317 svenska nyhetsartiklar, inklusive b√•de legitima nyheter och k√§nda desinformationsk√§llor.

## üìù Mer Information

## Project Overview
This project implements a machine learning model for detecting disinformation in Swedish news articles. The model can analyze both Swedish and English text (with automatic translation) to determine if an article is likely to contain disinformation.

## Latest Model Performance (BERT)
Our latest BERT model achieves significantly improved performance:
- Overall Accuracy: 77.1%
- Trustworthy News:
  - Precision: 88.5%
- Misleading News:
  - Recall: 85.6%

## Technical Details

### Model Architecture
- Base Model: KB/bert-base-swedish-cased (Swedish BERT)
- Fine-tuned on our custom dataset of Swedish news articles
- Supports both Swedish and English text input (with automatic translation)

### Dataset
The model is trained on a comprehensive dataset of Swedish news articles, including both legitimate news and known disinformation sources.

## Previous Models
The repository also includes our previous machine learning models based on TF-IDF and traditional ML approaches. These can be found in the legacy code.

## Recent Improvements

### 1. Enhanced Model Performance
- Increased accuracy to 74% with better balanced performance between classes
- Improved disinformation detection:
  - Precision: 82.1%
  - Recall: 70.2%
  - F1-score: 75.7%
- Better performance on trusted sources:
  - Precision: 66.4%
  - Recall: 79.3%
  - F1-score: 72.3%

### 2. Technical Improvements
- **Dataset Balancing**: Implemented SMOTE (Synthetic Minority Over-sampling Technique)
- **Hyperparameter Optimization**: Used GridSearchCV to find optimal parameters
- **Enhanced Feature Engineering**:
  - Increased TF-IDF features to 15,000
  - Extended n-gram range (1-3 words)
  - Implemented sublinear term frequency scaling
- **Multilingual Support**:
  - Automatic language detection
  - English-to-Swedish translation
  - Handles both languages seamlessly

### 3. Code Structure
- Implemented `NewsClassifier` class for better code organization
- Added comprehensive error handling
- Improved logging and progress reporting
- Better memory management for large datasets

## Installation

```bash
pip install -r requirements.txt
```

## Usage

```python
from model import NewsClassifier

# Initialize the classifier
classifier = NewsClassifier()

# Train the model
classifier.train()

# Make predictions
text = "Your news article text here..."
result = classifier.predict(text)
print(f"Prediction: {'Disinformation' if result['prediction'] == 0 else 'Trustworthy'}")
print(f"Confidence: {result['probability']:.2f}")
```

## Dataset
The model is trained on a comprehensive dataset of 38,317 Swedish news articles, including both legitimate news and known disinformation sources.

## Dependencies
- pandas
- numpy
- scikit-learn
- imbalanced-learn
- googletrans
- langdetect
- joblib

## Future Improvements
- Implementation of deep learning models
- Real-time web scraping capabilities
- API endpoint for easy integration
- Browser extension for automatic article checking
